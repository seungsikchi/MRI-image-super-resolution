import pickle
import os

from keras.datasets import mnist, cifar100,cifar10
from keras.preprocessing.image import ImageDataGenerator, load_img, save_img, img_to_array

import pandas as pd

import numpy as np
from os import walk, getcwd
import h5py

import scipy
from glob import glob

from keras.applications import vgg19
from keras import backend as K
from tensorflow.keras.utils import to_categorical
import voxel
import matplotlib.pyplot as plt
import pdb

class DataLoader():
    def __init__(self,img_res=(512, 512)):
        self.img_res = img_res

        self.load_batch()


    def load_data(self,batch_size=1, is_testing=False):
        path = glob('./raw/EPI/FLA/*')

        batch_images = np.random.choice(path, size=batch_size)

        imgs = []
        for img_path in batch_images:
            img = self.imread(img_path)
            # print(type(img))
            # print(img.shape)
            # plt.imshow(img[0], cmap = "gray")
            # plt.show()
            # if not is_testing:
            #     img = scipy.misc.imresize(img, self.img_res)

            #     if np.random.random() > 0.5:
            #         img = np.fliplr(img)
            # else:
            #     img = scipy.misc.imresize(img, self.img_res)
            imgs.append(img)

        imgs = np.array(imgs)/127.5 - 1.

        return imgs

    def load_batch(self, batch_size=1, is_testing=False):
        path_A = glob('./data/EPI/*')
        path_B = glob('./data/Routine/*')

        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)
        total_samples = self.n_batches * batch_size

        # Sample n_batches * batch_size from each path list so that model sees all
        # samples from both domains
        path_A = np.random.choice(path_A, total_samples, replace=False)
        path_B = np.random.choice(path_B, total_samples, replace=False)

        

        for i in range(self.n_batches-1):
            batch_A = path_A[i*batch_size:(i+1)*batch_size]
            batch_B = path_B[i*batch_size:(i+1)*batch_size]

            print(batch_A)
            print(batch_B)
            imgs_A, imgs_B = [], []
            for imgs_A, imgs_B in zip(batch_A, batch_B):
                imgs_A = self.imread(imgs_A)
                imgs_B = self.imread(imgs_B)

                print(imgs_A.shape)
                print(imgs_B.shape)


                print(imgs_A[0])
                print(imgs_B[0])

        
                resizedB = []

                N = len(imgs_A)
                B = len(imgs_B)

                for i in range(N):
                    resized = imgs_B.resize((256, 256))
                    npImg = np.array(resized)

                    if len(npImg.shape) == 3:
                        resizedB.append(npImg)
                
                imgs_B = np.array(resizedB)

            yield imgs_A, imgs_B

    def imread(self, path):
        vx = voxel.PyVoxel()
        x = vx.ReadFromRaw(path)
        x = vx.NormalizeMM
        x = vx.m_Voxel
        return x




def load_model(model_class, folder):
    
    with open(os.path.join(folder, 'params.pkl'), 'rb') as f:
        params = pickle.load(f)

    model = model_class(*params)

    model.load_weights(os.path.join(folder, 'weights/weights.h5'))

    return model
