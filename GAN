import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import pydicom
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers, optimizers


window_center = -600
window_width = 1600
 
#DICOM 형식으로 저장된 XRAY사진 읽기 
dicom_path = '.\\dataset\\CT_1\\1_MOD\\10001.DCM'
slice = pydicom.read_file(dicom_path)

# Rescale Slope, Window Center와 같은 DICOM 속성을 적용해주지 않으면 contrast 및 brightness 차이가 발생하게 되니 조심해야한다.
s = 1 # int(slice.RescaleSlope) # 기울기 RescaleSlope는 대부분 1
b = -1024 # int(slice.RescaleIntercept) # y 절편 간혹 -1024로 설정되어있는 경우가 있다 그러면 안좋음
image = s * slice.pixel_array + b
image = image.reshape(1,512,512,1)

batch_size = 1

def build_generator_model():
    model = tf.keras.Sequential() # Keras 모델 생성
	
    model.add(layers.Dense(1024, input_dim=100, use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())
    
    model.add(layers.Dense(32*32*128, use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    # Resahpe (32*32)
    model.add(layers.Reshape((32, 32, 128)))  
    model.add(layers.Conv2DTranspose(128, (2, 2), strides=(1, 1), padding='same', use_bias=False))
    model.add(layers.BatchNormalization()) 
    model.add(layers.UpSampling2D(size = (2, 2)))
    model.add(layers.LeakyReLU())

    # (32*32) -> (64*64)
    model.add(layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.UpSampling2D(size = (2, 2)))
    model.add(layers.LeakyReLU())
    
    # (256*256) -> (512*512)
    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))
    assert model.output_shape == (None, 512, 512, 1)
    return model


generator = build_generator_model()
generator.summary()

noise = tf.random.normal([1,100])
generated_image = generator(noise, training = False)

plt.imshow(generated_image[0, :, :, 0], cmap = 'gray')
plt.show()

def build_discriminator_model():

    model = tf.keras.Sequential()
    
    model.add(layers.Conv2D(12, (3, 3), strides=2, padding='same', input_shape=[512, 512, 1])) # input image size
    model.add(layers.LeakyReLU(0.2))
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(32, (3, 3), strides=2, padding='same'))
    model.add(layers.LeakyReLU(0.2))
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(64, (3, 3), strides=2, padding='same'))
    model.add(layers.LeakyReLU(0.2))
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (3, 3), strides=2, padding='same'))
    model.add(layers.LeakyReLU(0.2))
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    
    model.add(layers.Dense(256))
    model.add(layers.LeakyReLU(0.2))
    model.add(layers.Dropout(0.3))
    
    model.add(layers.Dense(512))
    model.add(layers.LeakyReLU(0.2))
    model.add(layers.Dropout(0.3))

    model.add(layers.Dense(1))
    
    return model

discriminator = build_discriminator_model()
discriminator.summary()

gan = keras.models.Sequential([generator, discriminator])

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)#cross_entropy를 크로스 엔트로피 손실함수로 지정

def discriminator_loss(real_output, fake_output):#판별자의 손실함수를 설정
  real_loss = cross_entropy(tf.ones_like(real_output), real_output)#정답의 손실함수
  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)#가짜의 손실함수
  total_loss = real_loss + fake_loss #정답과 가짜의 손실함를 합침
  return total_loss  #합친 손실함수값을 출력

def generator_loss(fake_output):
  return cross_entropy(tf.ones_like(fake_output), fake_output)#위에서 만든 가짜 손실함수의 값을 출력

generator_optimizer = tf.keras.optimizers.Adam(1e-4)#생성자 활섬화 함수 adam으로 설정
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)#판별자 활성화 함수 adam으로 설정

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)

batch_size = 1
epochs = 50
noise_dim = 100

def train_step(images):
    noise = tf.random.normal([batch_size, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: #gradientTape에 학습이 어떻게 되는지 저장
      generated_images = generator(noise, training=True)#생성자로 노이즈 이미지 생성

      images = images.reshape(1, 512, 512, 1)  
      real_output = discriminator(images, training=True)#정답 이미지를 판별자에 넣고 나온값을 real_output에 넣음
      fake_output = discriminator(generated_images, training=True)#생성자로 만들어진 이미지를 판별자에 넣고 나온값을 fake에 넣음

      gen_loss = generator_loss(fake_output)#생성자의 오차값을 측정해서 생성자 오차값에 넣음
      disc_loss = discriminator_loss(real_output, fake_output)#판별자의 오차값을 측정해서 판별자 오차값에 넣음
      d_loss = 0.5*np.add(gen_loss, disc_loss)
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)#생성자의 경사하강법 경사를 기록함
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)#판별자의 경사하강법 경사를 기록함

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))#경사가 나온걸 optimizer에 넣어서 역전파법실행
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))#경사가 나온걸 optimizer에 넣어서 역전파법실행
    print("gen_loss: %f"%d_loss[0])
    print("disc_loss: %d"%disc_loss)

test_noise = tf.random.normal([100, noise_dim]) #학습 시각화를 위한 테스트 노이즈

def show_generated_images(epoch):#이미지를 출려갛는 함수
    image = generator.predict(test_noise)
    image = 0.5 * image + 0.5

    plt.figure(figsize=(11, 11))

    i = 1
    for img in image:
        image = img.reshape(512, 512)
        plt.subplot(10, 10, i)
        plt.imshow(img, cmap = 'gray')
        plt.axis('off')
        i += 1
        
    plt.show()

def train(image, epochs):
    for epochs in range(epochs):# 전체 데이터 학습 반복 횟수(300)

        for image_batch in image: #batch 학습(64)
            train_step(image_batch)

        print("%s epochs trained" %epochs)

        if epochs % 5 == 0:
            show_generated_images(epochs)

train(image, epochs)
