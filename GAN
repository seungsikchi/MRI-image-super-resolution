import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D
from keras.layers.merge import _Merge
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras.utils import plot_model
from tensorflow.keras.initializers import RandomNormal

import numpy as np
import json
import os
import pickle as pkl
import matplotlib.pyplot as plt

import image_load as ds

class GAN():
    def __init__(self):
        self.epoch = 0
        self.d_losses = []
        self.g_losses = []
        self.z_dim = 100

        self._build_generator_model()

        # self._build_discriminator_model()
        # self._build_generator_model()

        # self._build_adversarial()

    def _build_generator_model(self):
        generator = tf.keras.Sequential([
            keras.layers.Dense(4 * 4 * 128, input_shape = [self.z_dim]),
            keras.layers.BatchNormalization(),
            keras.layers.LeakyReLU(alpha= 0.2),
            keras.layers.Reshape((4, 4, 128)),
            keras.layers.UpSampling2D(size = (2,2)),
            keras.layers.Conv2DTranspose(64, kernel_size = 5, strides =2, padding = "same", activation = "selu"),
            keras.layers.BatchNormalization(),
            keras.layers.UpSampling2D(size = (2,2)),
            keras.layers.Conv2DTranspose(32, kernel_size = 5, strides =2, padding = "same", activation = "relu"),
            keras.layers.BatchNormalization(),
            keras.layers.UpSampling2D(size = (2,2)),
            keras.layers.Conv2DTranspose(16, kernel_size = 5, strides =2, padding = "same", activation = "relu"),
            keras.layers.BatchNormalization(),
             keras.layers.Conv2DTranspose(1, kernel_size = 5, strides =2, padding = "same", activation = "tanh"),
        ]) # Keras 모델 생성
        generator.summary()
        return generator

    def _build_discriminator_model(self):

        model = tf.keras.Sequential()

        discriminator_input = Input(shape = (256, 256, 12))
        
        model.add(layers.Conv2D(12, (3, 3), strides=2, padding='same', input_shape=[512, 512, 1])) # input image size
        model.add(layers.ReLU(0.2))
        model.add(layers.Dropout(0.3))

        model.add(layers.Conv2D(32, (3, 3), strides=2, padding='same'))
        model.add(layers.ReLU(0.2))
        model.add(layers.Dropout(0.3))

        model.add(layers.Conv2D(64, (3, 3), strides=2, padding='same'))
        model.add(layers.ReLU(0.2))
        model.add(layers.Dropout(0.3))

        model.add(layers.Conv2D(128, (3, 3), strides=2, padding='same'))
        model.add(layers.ReLU(0.2))
        model.add(layers.Dropout(0.3))

        model.add(layers.Conv2D(256, (3, 3), strides=2, padding='same'))
        model.add(layers.ReLU(0.2))
        model.add(layers.Dropout(0.3))

        model.add(layers.Conv2D(512, (3, 3), strides=2, padding='same'))
        model.add(layers.ReLU(0.2))
        model.add(layers.Dropout(0.3))

        model.add(layers.Flatten())
        
        model.add(layers.Dense(512))
        model.add(layers.ReLU(0.2))
        model.add(layers.Dropout(0.3))

        discriminator_output = model.add(layers.Dense(1))

        self.discriminator = Model(discriminator_input, discriminator_output)
        
        return model

    def set_trainable(self, m, val):
        m.trainable = val
        for l in m.layers:
            l.trainable = val

    def _build_adversarial(self):
        
        self.discriminator.compile(optimizers = 'adam', loss = 'binary_crossentropy', metrics = ['accuaray'])


        self.set_trainable(self.discriminator, False)
        model_input = Input(shape=(100), name = 'model_input')
        model_output = self._build_discriminator_model(self._build_generator_model(model_input))
        self.model = Model(model_input, model_output)

        self.model.compile(optimizers = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
        
        self.set_trainable(self._build_discriminator_model, True)

    def train_discriminator(self, train_x, batch_size, using_generator):
    
        valid = np.ones((batch_size,1))
        fake = np.zeros((batch_size,1))

        if using_generator:
            true_imgs = next(train_x)[0]
            if true_imgs.shape[0] != batch_size:
                true_imgs = next(train_x)[0]
        else:
            idx = np.random.randint(0, train_x.shape[0], batch_size)
            true_imgs = train_x[idx]
        
        noise = np.random.normal(0, 1, (batch_size, self.z_dim))
        gen_imgs = self._build_generator_model.predict(noise)

        d_loss_real, d_acc_real =   self._build_discriminator_model.train_on_batch(true_imgs, valid)
        d_loss_fake, d_acc_fake =   self._build_discriminator_model.train_on_batch(gen_imgs, fake)
        d_loss =  0.5 * (d_loss_real + d_loss_fake)
        d_acc = 0.5 * (d_acc_real + d_acc_fake)

        return [d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake]

    def train_generator(self, batch_size):
        valid = np.ones((batch_size,1))
        noise = np.random.normal(0, 1, (batch_size, self.z_dim))
        return self.model.train_on_batch(noise, valid)

    def train(self,train_x, batch_size, epochs, using_generator = False):

        for i in range(self.epoch, self.epoch + epochs):

            d = self.train_discriminator(train_x, batch_size, using_generator)
            g = self.train_generator(batch_size)

            print ("%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]" % (epoch, d[0], d[1], d[2], d[3], d[4], d[5], g[0], g[1]))

            self.d_losses.append(d)
            self.g_losses.append(g)

            self.epoch += 1

    

path = '.\\image\\dataset1\\'
ds = ds.dataSet(path)
train_x = ds.load_data(0.3)
Batch_size = 10
Epochs = 1000

gan = GAN()

print(train_x.shape)


noise = tf.random.normal([1,100])
generated_image = generator(noise, training = False)

plt.imshow(generated_image[0, :, :, 0], cmap = 'gray')
plt.show()

gan.train(train_x, Batch_size, Epochs)



    
