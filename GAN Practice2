import sys
import numpy as np
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers.advanced_activations import LeakyReLU
from keras.layers import BatchNormalization
from keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import plot_model
from tensorflow.keras.datasets import mnist
from random import randint
import matplotlib.pyplot as plt

class Discriminator(object):
    def __init__(self, width = 512, height = 512, channels = 1, latent_size = 100):
        self.CAPACITY = width * height * channels
        self.SHAPE = (width, height, channels)
        self.OPTIMIZER = Adam(lr=0.0002, decay = 8e-9)

        self.Discriminator = self.model()
        self.Discriminator.compile(loss = 'binary_crossentropy', optimizer = self.OPTIMIZER)
        self.summary()

    def model(self):
        model = Sequential()
        model.add(Flatten(input_shape = self.SHAPE))
        model.add(Dense(self.CAPACITY, input_shape = self.SHAPE))
        model.add(LeakyReLU(alpha = 0.2))
        model.add(LeakyReLU(alpha = 0.2))
        model.add(Dense(1, activation = 'sigmoid'))
        return model

    def summary(self):
        return self.Discriminator.summary()


class Generator(object):
    def __init__(self, width = 28, height = 28, channels = 1, latent_size = 100):
        self.W = width
        self.H = height
        self.C = channels
        self.OPTIMIZER = Adam(lr = 0.0002, decay = 8e-9)

        self.LATENT_SPACE_SIZE = latent_size
        self.latent_space = np.random.normal(0.1,(self.LATENT_SPACE_SIZE))

        self.Generator = self.model()
        self.Generator.compile(loss = 'binary_crossentropy', optimizers = self.OPTIMIZER)
        self.summary()

    def model(self, block_starting_size = 128, num_block = 4):
        model = Sequential()

        block_size = block_starting_size
        model.add(Dense(block_size, input_shape = (self.LATENT_SPACE_SIZE)))
        model.add(LeakyReLU(alpht = 0.2))
        model.add(BatchNormalization(momentum=0.8))

        for i in range(num_block-1):
            block_size = block_size * 2
            model.add(Dense(block_size))
            model.add(LeakyReLU(alpha = 0.2))
            model.add(BatchNormalization(momentum = 0.8))

        model.add(Dense(self.W, self.H, self.C, activation = 'tanh'))
        model.add(Reshape((self.W, self.H, self.C)))

        return model
    
    def summary(self):
        return self.Generator.summary()


class GAN(object):
    def __init__(self, discriminator, generator):
        self.OPTIMIZER = Adam(lr = 0.0002, decay = 8e-9)
        self.Generator = generator
        self.Disciriminator = discriminator
        self.Disciriminator.trainable = False

        self.gan_model = self.model()
        self.gan_model.compile(loss = 'binary_crossentropy', optimizers = self.OPTIMIZER)
        self.summary()

    def model(self):
        model = Sequential()
        model.add(self.Generator)
        model.add(self.Disciriminator)
        return model

    def summary(self):
        return self.gan_model.summary()


class Trainer:
    def __init__(self, width = 512, height = 512, channels = 1, latent_size = 100, epochs =50000, batch = 32, checkpoint = 50, model_type = -1):
        self.W = width
        self.H = height
        self.C = channels
        self.EPOCHS = epochs
        self.BATCH = batch
        self.CHECKPOINT = checkpoint
        self.model_type = model_type

        self.LATENT_SPACE_SIZE = latent_size
        
        self.generator = Generator(height = self.H, width = self.W, channels = self.C, latent_size = self.LATENT_SPACE_SIZE)
        self.discriminator = Discriminator(height = self.H, width = self.W, channels = self.C)
        self.gan = GAN(generator = self.generator.Generator, discriminator= self.discriminator.Discriminator)
        
        self.lead_data()

    def lead_data():
        path = './image/dataset1'
        dl = dl.dataSet(path)
        train_x = dl.load_data
        return train_x

    def train(self):
        for e in range(self.EPOCHS):
            count_real_images = int(self.BATCH/2)
            starting_index = randint(0, (len(self.X_train)-count_real_images))
            real_image_raw = self.X_train[ starting_index: (starting_index + count_real_images)]
            x_real_images = real_image_raw.reshape( count_real_images, self.W, self.H, self.C)

            y_read_label = np.ones([count_real_images])

            latent_spaece_samples = self.smaple_latent_space(count_real_images)
            x_generated_images = self.generator.Generator.predict(latent_spaece_samples)

            y_generated_labels = self.generator.Generator.predict(latent_spaece_samples)

            x_batch = np.concatenate( [x_real_images, x_generated_images])
            y_batch = np.concatenate( [y_read_label, y_generated_labels])

            discriminator_loss = self.discriminator.Discriminator.train_on_batch(x_batch, y_batch)

            if e % 5 == 0:
                x_latent_space_samples = self.sample_latent_space(self.BATCH)
                y_generated_labels = np.ones([self.BATCH,1])
                generator_loss = self.gan_model.train_on_batch(x_latent_space_samples, y_generated_labels)


            if e % self.CHECKPOINT == 0:
                print('Epoch: '+str(int(e))+', [Discriminator :: Loss: '+str(discriminator_loss)+'], [ Generator :: Loss: '+str(generator_loss)+']')
                self.plot_checkpoint(e)

    def sample_latent_space(self, instances):
        return np.random.normal(0, 1, (instances, self.LATENT_SPACE_SIZE))

    def plot_checkpoint(self, e):
        noise = self.sample_latent_space(16)
        images = self.generator.Generator.predict(noise)

        plt.figure(figsize = (4,4))
        for i in range(images.shape[0]):
            plt.subplot(4, 4, i+1)
            image = images[i, :, :, :]
            image = (image * 127.5) + 127.5
            image =np.reshape(image * 255.0, [self.H, self.W])
            plt.imshow(image, cmap = 'gray')
            plt.axis('off')

        plt.tight_layout()
        plt.show()
        return

# Command Line Argument Method
HEIGHT  = 28
WIDTH   = 28
CHANNEL = 1
LATENT_SPACE_SIZE = 100
EPOCHS = 5000
BATCH = 32
CHECKPOINT = 100
MODEL_TYPE = 3

trainer = Trainer(height=HEIGHT,\
                 width=WIDTH,\
                 channels=CHANNEL,\
                 latent_size=LATENT_SPACE_SIZE,\
                 epochs =EPOCHS,\
                 batch=BATCH,\
                 checkpoint=CHECKPOINT,
                 model_type=MODEL_TYPE)
